{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: seaborn in /home/meron/.local/lib/python3.10/site-packages (0.13.2)\n",
      "Requirement already satisfied: pandas>=1.2 in /home/meron/.local/lib/python3.10/site-packages (from seaborn) (2.1.4)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /home/meron/.local/lib/python3.10/site-packages (from seaborn) (3.8.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /home/meron/.local/lib/python3.10/site-packages (from seaborn) (1.26.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/meron/.local/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/meron/.local/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.1.1)\n",
      "Requirement already satisfied: pillow>=8 in /home/meron/.local/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.1.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/meron/.local/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.46.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/meron/.local/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/meron/.local/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (23.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/meron/.local/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/meron/.local/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/meron/.local/lib/python3.10/site-packages (from pandas>=1.2->seaborn) (2023.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas>=1.2->seaborn) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from process_data import  get_df\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "pd.set_option('display.float_format', lambda x: '%.0f' % x)\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bearer Id</th>\n",
       "      <th>Start</th>\n",
       "      <th>Start ms</th>\n",
       "      <th>End</th>\n",
       "      <th>End ms</th>\n",
       "      <th>Dur. (ms)</th>\n",
       "      <th>IMSI</th>\n",
       "      <th>MSISDN/Number</th>\n",
       "      <th>IMEI</th>\n",
       "      <th>Last Location Name</th>\n",
       "      <th>...</th>\n",
       "      <th>Youtube DL (Bytes)</th>\n",
       "      <th>Youtube UL (Bytes)</th>\n",
       "      <th>Netflix DL (Bytes)</th>\n",
       "      <th>Netflix UL (Bytes)</th>\n",
       "      <th>Gaming DL (Bytes)</th>\n",
       "      <th>Gaming UL (Bytes)</th>\n",
       "      <th>Other DL (Bytes)</th>\n",
       "      <th>Other UL (Bytes)</th>\n",
       "      <th>Total UL (Bytes)</th>\n",
       "      <th>Total DL (Bytes)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13114483460844900352</td>\n",
       "      <td>4/4/2019 12:01</td>\n",
       "      <td>770</td>\n",
       "      <td>4/25/2019 14:35</td>\n",
       "      <td>662</td>\n",
       "      <td>1823652</td>\n",
       "      <td>208201448079117</td>\n",
       "      <td>33664962239</td>\n",
       "      <td>35521209507511</td>\n",
       "      <td>9.16456699548519E+015</td>\n",
       "      <td>...</td>\n",
       "      <td>15854611</td>\n",
       "      <td>2501332</td>\n",
       "      <td>8198936</td>\n",
       "      <td>9656251</td>\n",
       "      <td>278082303</td>\n",
       "      <td>14344150</td>\n",
       "      <td>171744450</td>\n",
       "      <td>8814393</td>\n",
       "      <td>36749741</td>\n",
       "      <td>308879636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13114483482878900224</td>\n",
       "      <td>4/9/2019 13:04</td>\n",
       "      <td>235</td>\n",
       "      <td>4/25/2019 8:15</td>\n",
       "      <td>606</td>\n",
       "      <td>1365104</td>\n",
       "      <td>208201909211140</td>\n",
       "      <td>33681854413</td>\n",
       "      <td>35794009006359</td>\n",
       "      <td>L77566A</td>\n",
       "      <td>...</td>\n",
       "      <td>20247395</td>\n",
       "      <td>19111729</td>\n",
       "      <td>18338413</td>\n",
       "      <td>17227132</td>\n",
       "      <td>608750074</td>\n",
       "      <td>1170709</td>\n",
       "      <td>526904238</td>\n",
       "      <td>15055145</td>\n",
       "      <td>53800391</td>\n",
       "      <td>653384965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13114483484080500736</td>\n",
       "      <td>4/9/2019 17:42</td>\n",
       "      <td>1</td>\n",
       "      <td>4/25/2019 11:58</td>\n",
       "      <td>652</td>\n",
       "      <td>1361762</td>\n",
       "      <td>208200314458056</td>\n",
       "      <td>33760627129</td>\n",
       "      <td>35281510359387</td>\n",
       "      <td>D42335A</td>\n",
       "      <td>...</td>\n",
       "      <td>19725661</td>\n",
       "      <td>14699576</td>\n",
       "      <td>17587794</td>\n",
       "      <td>6163408</td>\n",
       "      <td>229584621</td>\n",
       "      <td>395630</td>\n",
       "      <td>410692588</td>\n",
       "      <td>4215763</td>\n",
       "      <td>27883638</td>\n",
       "      <td>279807335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13114483485442799616</td>\n",
       "      <td>4/10/2019 0:31</td>\n",
       "      <td>486</td>\n",
       "      <td>4/25/2019 7:36</td>\n",
       "      <td>171</td>\n",
       "      <td>1321509</td>\n",
       "      <td>208201402342131</td>\n",
       "      <td>33750343200</td>\n",
       "      <td>35356610164913</td>\n",
       "      <td>T21824A</td>\n",
       "      <td>...</td>\n",
       "      <td>21388122</td>\n",
       "      <td>15146643</td>\n",
       "      <td>13994646</td>\n",
       "      <td>1097942</td>\n",
       "      <td>799538153</td>\n",
       "      <td>10849722</td>\n",
       "      <td>749039933</td>\n",
       "      <td>12797283</td>\n",
       "      <td>43324218</td>\n",
       "      <td>846028530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13114483499480700928</td>\n",
       "      <td>4/12/2019 20:10</td>\n",
       "      <td>565</td>\n",
       "      <td>4/25/2019 10:40</td>\n",
       "      <td>954</td>\n",
       "      <td>1089009</td>\n",
       "      <td>208201401415120</td>\n",
       "      <td>33699795932</td>\n",
       "      <td>35407009745539</td>\n",
       "      <td>D88865A</td>\n",
       "      <td>...</td>\n",
       "      <td>15259380</td>\n",
       "      <td>18962873</td>\n",
       "      <td>17124581</td>\n",
       "      <td>415218</td>\n",
       "      <td>527707248</td>\n",
       "      <td>3529801</td>\n",
       "      <td>550709500</td>\n",
       "      <td>13910322</td>\n",
       "      <td>38542814</td>\n",
       "      <td>569138589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149996</th>\n",
       "      <td>7277825670196679680</td>\n",
       "      <td>4/29/2019 7:28</td>\n",
       "      <td>451</td>\n",
       "      <td>4/30/2019 6:02</td>\n",
       "      <td>214</td>\n",
       "      <td>81230</td>\n",
       "      <td>208202201200072</td>\n",
       "      <td>33650688697</td>\n",
       "      <td>35483109451938</td>\n",
       "      <td>D20434A</td>\n",
       "      <td>...</td>\n",
       "      <td>16191667</td>\n",
       "      <td>11763428</td>\n",
       "      <td>17883703</td>\n",
       "      <td>19678161</td>\n",
       "      <td>526609673</td>\n",
       "      <td>9197207</td>\n",
       "      <td>3264510</td>\n",
       "      <td>13487416</td>\n",
       "      <td>57628851</td>\n",
       "      <td>574175259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149997</th>\n",
       "      <td>7349883264234609664</td>\n",
       "      <td>4/29/2019 7:28</td>\n",
       "      <td>483</td>\n",
       "      <td>4/30/2019 10:41</td>\n",
       "      <td>187</td>\n",
       "      <td>97970</td>\n",
       "      <td>208201908153249</td>\n",
       "      <td>33663449963</td>\n",
       "      <td>35660508296467</td>\n",
       "      <td>D10223C</td>\n",
       "      <td>...</td>\n",
       "      <td>13877234</td>\n",
       "      <td>8288284</td>\n",
       "      <td>19350146</td>\n",
       "      <td>21293148</td>\n",
       "      <td>626893062</td>\n",
       "      <td>4735033</td>\n",
       "      <td>712180387</td>\n",
       "      <td>2457758</td>\n",
       "      <td>39135081</td>\n",
       "      <td>666648844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149998</th>\n",
       "      <td>13114483573367300096</td>\n",
       "      <td>4/29/2019 7:28</td>\n",
       "      <td>283</td>\n",
       "      <td>4/30/2019 10:46</td>\n",
       "      <td>810</td>\n",
       "      <td>98249</td>\n",
       "      <td>208201711161187</td>\n",
       "      <td>33621890103</td>\n",
       "      <td>35721209870907</td>\n",
       "      <td>T51102A</td>\n",
       "      <td>...</td>\n",
       "      <td>22660510</td>\n",
       "      <td>1855903</td>\n",
       "      <td>9963942</td>\n",
       "      <td>5065760</td>\n",
       "      <td>553539484</td>\n",
       "      <td>13394316</td>\n",
       "      <td>121100856</td>\n",
       "      <td>11314729</td>\n",
       "      <td>34912224</td>\n",
       "      <td>592786405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149999</th>\n",
       "      <td>13114483573367300096</td>\n",
       "      <td>4/29/2019 7:28</td>\n",
       "      <td>696</td>\n",
       "      <td>4/30/2019 10:40</td>\n",
       "      <td>327</td>\n",
       "      <td>97910</td>\n",
       "      <td>208202101098075</td>\n",
       "      <td>33619622058</td>\n",
       "      <td>86186204011457</td>\n",
       "      <td>L88342B</td>\n",
       "      <td>...</td>\n",
       "      <td>8817106</td>\n",
       "      <td>8305402</td>\n",
       "      <td>3322253</td>\n",
       "      <td>13172589</td>\n",
       "      <td>352536971</td>\n",
       "      <td>2529475</td>\n",
       "      <td>814713113</td>\n",
       "      <td>1406930</td>\n",
       "      <td>29626096</td>\n",
       "      <td>371895920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150000</th>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>11634073</td>\n",
       "      <td>11009410</td>\n",
       "      <td>11626852</td>\n",
       "      <td>11001755</td>\n",
       "      <td>422044703</td>\n",
       "      <td>8288398</td>\n",
       "      <td>421100544</td>\n",
       "      <td>8264799</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150001 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Bearer Id            Start  Start ms              End  \\\n",
       "0      13114483460844900352   4/4/2019 12:01       770  4/25/2019 14:35   \n",
       "1      13114483482878900224   4/9/2019 13:04       235   4/25/2019 8:15   \n",
       "2      13114483484080500736   4/9/2019 17:42         1  4/25/2019 11:58   \n",
       "3      13114483485442799616   4/10/2019 0:31       486   4/25/2019 7:36   \n",
       "4      13114483499480700928  4/12/2019 20:10       565  4/25/2019 10:40   \n",
       "...                     ...              ...       ...              ...   \n",
       "149996  7277825670196679680   4/29/2019 7:28       451   4/30/2019 6:02   \n",
       "149997  7349883264234609664   4/29/2019 7:28       483  4/30/2019 10:41   \n",
       "149998 13114483573367300096   4/29/2019 7:28       283  4/30/2019 10:46   \n",
       "149999 13114483573367300096   4/29/2019 7:28       696  4/30/2019 10:40   \n",
       "150000                  NaN             None       NaN             None   \n",
       "\n",
       "        End ms  Dur. (ms)            IMSI  MSISDN/Number           IMEI  \\\n",
       "0          662    1823652 208201448079117    33664962239 35521209507511   \n",
       "1          606    1365104 208201909211140    33681854413 35794009006359   \n",
       "2          652    1361762 208200314458056    33760627129 35281510359387   \n",
       "3          171    1321509 208201402342131    33750343200 35356610164913   \n",
       "4          954    1089009 208201401415120    33699795932 35407009745539   \n",
       "...        ...        ...             ...            ...            ...   \n",
       "149996     214      81230 208202201200072    33650688697 35483109451938   \n",
       "149997     187      97970 208201908153249    33663449963 35660508296467   \n",
       "149998     810      98249 208201711161187    33621890103 35721209870907   \n",
       "149999     327      97910 208202101098075    33619622058 86186204011457   \n",
       "150000     NaN        NaN             NaN            NaN            NaN   \n",
       "\n",
       "           Last Location Name  ...  Youtube DL (Bytes)  Youtube UL (Bytes)  \\\n",
       "0       9.16456699548519E+015  ...            15854611             2501332   \n",
       "1                     L77566A  ...            20247395            19111729   \n",
       "2                     D42335A  ...            19725661            14699576   \n",
       "3                     T21824A  ...            21388122            15146643   \n",
       "4                     D88865A  ...            15259380            18962873   \n",
       "...                       ...  ...                 ...                 ...   \n",
       "149996                D20434A  ...            16191667            11763428   \n",
       "149997                D10223C  ...            13877234             8288284   \n",
       "149998                T51102A  ...            22660510             1855903   \n",
       "149999                L88342B  ...             8817106             8305402   \n",
       "150000                   None  ...            11634073            11009410   \n",
       "\n",
       "        Netflix DL (Bytes)  Netflix UL (Bytes)  Gaming DL (Bytes)  \\\n",
       "0                  8198936             9656251          278082303   \n",
       "1                 18338413            17227132          608750074   \n",
       "2                 17587794             6163408          229584621   \n",
       "3                 13994646             1097942          799538153   \n",
       "4                 17124581              415218          527707248   \n",
       "...                    ...                 ...                ...   \n",
       "149996            17883703            19678161          526609673   \n",
       "149997            19350146            21293148          626893062   \n",
       "149998             9963942             5065760          553539484   \n",
       "149999             3322253            13172589          352536971   \n",
       "150000            11626852            11001755          422044703   \n",
       "\n",
       "        Gaming UL (Bytes)  Other DL (Bytes)  Other UL (Bytes)  \\\n",
       "0                14344150         171744450           8814393   \n",
       "1                 1170709         526904238          15055145   \n",
       "2                  395630         410692588           4215763   \n",
       "3                10849722         749039933          12797283   \n",
       "4                 3529801         550709500          13910322   \n",
       "...                   ...               ...               ...   \n",
       "149996            9197207           3264510          13487416   \n",
       "149997            4735033         712180387           2457758   \n",
       "149998           13394316         121100856          11314729   \n",
       "149999            2529475         814713113           1406930   \n",
       "150000            8288398         421100544           8264799   \n",
       "\n",
       "        Total UL (Bytes)  Total DL (Bytes)  \n",
       "0               36749741         308879636  \n",
       "1               53800391         653384965  \n",
       "2               27883638         279807335  \n",
       "3               43324218         846028530  \n",
       "4               38542814         569138589  \n",
       "...                  ...               ...  \n",
       "149996          57628851         574175259  \n",
       "149997          39135081         666648844  \n",
       "149998          34912224         592786405  \n",
       "149999          29626096         371895920  \n",
       "150000               NaN               NaN  \n",
       "\n",
       "[150001 rows x 55 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_df()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start by identifying the top 10 handsets used by the customers\n",
    "Handset_counts = df['Handset Type'].value_counts()\n",
    "Handset_counts = Handset_counts .reset_index()\n",
    "Handset_counts.columns = ['Handset Type', 'Count']\n",
    "Handset_counts.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify the top 3 handset manufacturers\n",
    "manufacturers_counts = df['Handset Manufacturer'].value_counts()\n",
    "manufacturers_counts = manufacturers_counts .reset_index()\n",
    "manufacturers_counts.columns = ['top 3 handset manufacturers', 'Count']\n",
    "manufacturers_counts.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify the top 5 handsets per top 3 handset manufacturer\n",
    "# first filter the data \n",
    "filtered_df = df[df['Handset Manufacturer'].isin(['Apple', 'Samsung', 'Huawei'])]\n",
    "filtered_df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify the top 5 handsets per top 3 handset manufacturer\n",
    "Handset_counts = filtered_df['Handset Type'].value_counts()\n",
    "Handset_counts = Handset_counts .reset_index()\n",
    "Handset_counts.columns = ['top 5 handsets', 'Count']\n",
    "Handset_counts.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate per user the following information in the column  \n",
    "# number of xDR sessions\n",
    "# Session duration\n",
    "# the total download (DL) and upload (UL) data\n",
    "# the total data volume (in Bytes) during this session for each application\n",
    "\n",
    "# Convert 'Start' and 'End' columns to datetime format for better handling\n",
    "df['Start'] = pd.to_datetime(df['Start'])\n",
    "df['End'] = pd.to_datetime(df['End'])\n",
    "\n",
    "# Calculate Session Duration in seconds\n",
    "df['Session Duration (s)'] = (df['End'] - df['Start']).dt.total_seconds()\n",
    "\n",
    "# List of applications for which you want to calculate total data volume\n",
    "applications = ['Social Media', 'Google', 'Email', 'Youtube', 'Netflix', 'Gaming', 'Other']\n",
    "\n",
    "# Aggregate per user\n",
    "user_aggregated = df.groupby('MSISDN/Number').agg({\n",
    "    'Bearer Id': 'count',  # Number of xDR sessions\n",
    "    'Session Duration (s)': 'sum',  # Total session duration\n",
    "    'Total DL (Bytes)': 'sum',  # Total download data\n",
    "    'Total UL (Bytes)': 'sum',  # Total upload data\n",
    "    **{f'{app} DL (Bytes)': 'sum' for app in applications},  # Total download data for each application\n",
    "    **{f'{app} UL (Bytes)': 'sum' for app in applications}  # Total upload data for each application\n",
    "})\n",
    "\n",
    "# Concatenate download and upload columns for each application\n",
    "for app in applications:\n",
    "    user_aggregated[f'{app} (Total Bytes)'] = user_aggregated[f'{app} DL (Bytes)'] + user_aggregated[f'{app} UL (Bytes)']\n",
    "    user_aggregated.drop([f'{app} DL (Bytes)', f'{app} UL (Bytes)'], axis=1, inplace=True)\n",
    "\n",
    "# Rename columns for clarity\n",
    "user_aggregated.rename(columns={'Bearer Id': 'Number of xDR sessions'}, inplace=True)\n",
    "\n",
    "# Display the aggregated information\n",
    "user_aggregated.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = df.isnull()\n",
    "missing_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values_count = df.isnull().sum()\n",
    "missing_values_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Conduct an exploratory data analysis on those data & communicate useful insights. Ensure that you \n",
    "# identify and treat all missing values and outliers in the dataset by replacing by the mean of the corresponding column.\n",
    "\n",
    "non_numeric_columns = df.select_dtypes(exclude=['number']).columns\n",
    "\n",
    "df_numeric = df.drop(non_numeric_columns, axis=1)\n",
    "\n",
    "cleaned_data = df_numeric.fillna(df_numeric.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the basic metrics (mean, median, etc) in the Dataset (explain) & their importance for the global objective.\n",
    "selected_columns = [\n",
    "    \"Dur. (ms)\",\n",
    "    \"Avg Bearer TP DL (kbps)\",\n",
    "    \"Avg Bearer TP UL (kbps)\",\n",
    "    \"Social Media DL (Bytes)\",\n",
    "    \"Social Media UL (Bytes)\",\n",
    "    \"Google DL (Bytes)\",\n",
    "    \"Google UL (Bytes)\",\n",
    "    \"Email DL (Bytes)\",\n",
    "    \"Email UL (Bytes)\",\n",
    "    \"Youtube DL (Bytes)\",\n",
    "    \"Youtube UL (Bytes)\",\n",
    "    \"Netflix DL (Bytes)\",\n",
    "    \"Netflix UL (Bytes)\",\n",
    "    \"Gaming DL (Bytes)\",\n",
    "    \"Gaming UL (Bytes)\",\n",
    "    \"Total UL (Bytes)\",\n",
    "    \"Total DL (Bytes)\",\n",
    "    \"Other DL (Bytes)\",\n",
    "    \"Other UL (Bytes)\"\n",
    "]\n",
    "\n",
    "# Create a new DataFrame with selected columns\n",
    "displayed_data = cleaned_data[selected_columns]\n",
    "\n",
    "# Display the new DataFrame\n",
    "displayed_data.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Conduct a Non-Graphical Univariate Analysis by computing dispersion parameters for each quantitative \n",
    "# variable and provide useful interpretation. \n",
    "\n",
    "quantitative_columns = displayed_data.select_dtypes(include=['number']).columns\n",
    "\n",
    "dispersion_data = pd.DataFrame(index=quantitative_columns, columns=['Range', 'Variance', 'Standard Deviation', 'IQR'])\n",
    "\n",
    "for column in quantitative_columns:\n",
    "    data = displayed_data[column].dropna() \n",
    "   \n",
    "    data_range = data.max() - data.min()\n",
    "    \n",
    "    data_variance = data.var()\n",
    "    \n",
    "    data_std_dev = data.std()\n",
    "    \n",
    "    # Interquartile Range (IQR)\n",
    "    data_iqr = data.quantile(0.75) - data.quantile(0.25)\n",
    "    \n",
    "    # Store values in the DataFrame\n",
    "    dispersion_data.loc[column] = [data_range, data_variance, data_std_dev, data_iqr]\n",
    "\n",
    "dispersion_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "numeric_columns = displayed_data.select_dtypes(include='number').columns\n",
    "\n",
    "for column in numeric_columns:\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.hist(df[column].dropna(), bins=30, color='skyblue', edgecolor='black')\n",
    "    plt.title(f'Histogram of {column}')\n",
    "    plt.xlabel(column)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# List of applications\n",
    "applications = [\n",
    "    'Social Media',\n",
    "    'Google',\n",
    "    'Email',\n",
    "    'Youtube',\n",
    "    'Netflix',\n",
    "    'Gaming',\n",
    "    'Other',\n",
    "]\n",
    "\n",
    "# Calculate total DL+UL data\n",
    "cleaned_data['Total Data (DL+UL)'] = cleaned_data['Total UL (Bytes)'] + cleaned_data['Total DL (Bytes)']\n",
    "\n",
    "# Create scatter plots for each application vs. Total Data (DL+UL)\n",
    "plt.figure(figsize=(14, 10))\n",
    "for app in applications:\n",
    "    sns.scatterplot(x=cleaned_data[app + ' DL (Bytes)'], y=cleaned_data[app + ' UL (Bytes)'], label=app)\n",
    "\n",
    "plt.xlabel('DL Data (Bytes)')\n",
    "plt.ylabel('UL Data (Bytes)')\n",
    "plt.title('Scatter Plot of DL vs. UL Data for Each Application')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Start' and 'End' columns to datetime format for better handling\n",
    "\n",
    "df['Start'] = pd.to_datetime(df['Start'])\n",
    "df['End'] = pd.to_datetime(df['End'])\n",
    "\n",
    "# Calculate Session Duration in seconds\n",
    "df['Session Duration (s)'] = (df['End'] - df['Start']).dt.total_seconds()\n",
    "\n",
    "# Calculate total DL+UL data\n",
    "df['Total Data (DL+UL)'] = df['Total UL (Bytes)'] + df['Total DL (Bytes)']\n",
    "\n",
    "# Group users into deciles based on total session duration\n",
    "df['Duration Decile'] = pd.qcut(df.groupby('MSISDN/Number')['Session Duration (s)'].transform('sum'), q=10, labels=False, duplicates='drop')\n",
    "\n",
    "# Group by duration decile and compute total data per decile\n",
    "decile_data = df.groupby('Duration Decile')['Total Data (DL+UL)'].sum().reset_index()\n",
    "\n",
    "# Sort deciles by total data in descending order\n",
    "decile_data = decile_data.sort_values(by='Total Data (DL+UL)', ascending=False)\n",
    "\n",
    "# Display the total data per decile\n",
    "print(decile_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# List of columns for correlation analysis\n",
    "columns_of_interest = [\n",
    "    'Social Media DL (Bytes)',\n",
    "    'Google DL (Bytes)',\n",
    "    'Email DL (Bytes)',\n",
    "    'Youtube DL (Bytes)',\n",
    "    'Netflix DL (Bytes)',\n",
    "    'Gaming DL (Bytes)',\n",
    "    'Other DL (Bytes)',\n",
    "    'Social Media UL (Bytes)',\n",
    "    'Google UL (Bytes)',\n",
    "    'Email UL (Bytes)',\n",
    "    'Youtube UL (Bytes)',\n",
    "    'Netflix UL (Bytes)',\n",
    "    'Gaming UL (Bytes)',\n",
    "    'Other UL (Bytes)',\n",
    "]\n",
    "\n",
    "# Subset the DataFrame with the specified columns\n",
    "correlation_data = cleaned_data[columns_of_interest]\n",
    "\n",
    "# Calculate correlation matrix\n",
    "correlation_matrix = correlation_data.corr()\n",
    "\n",
    "# Display the correlation matrix\n",
    "\n",
    "correlation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select relevant columns\n",
    "app_columns = ['Social Media DL (Bytes)', 'Social Media UL (Bytes)',\n",
    "               'Google DL (Bytes)', 'Google UL (Bytes)',\n",
    "               'Email DL (Bytes)', 'Email UL (Bytes)',\n",
    "               'Youtube DL (Bytes)', 'Youtube UL (Bytes)',\n",
    "               'Netflix DL (Bytes)', 'Netflix UL (Bytes)',\n",
    "               'Gaming DL (Bytes)', 'Gaming UL (Bytes)',\n",
    "               'Other DL (Bytes)', 'Other UL (Bytes)']\n",
    "\n",
    "# Create new columns for total bytes for each application\n",
    "for app in ['Social Media', 'Google', 'Email', 'Youtube', 'Netflix', 'Gaming', 'Other', 'Total']:\n",
    "    cleaned_data[f'{app} Total Bytes'] = cleaned_data[f'{app} DL (Bytes)'] + cleaned_data[f'{app} UL (Bytes)']\n",
    "\n",
    "# Select only the new total bytes columns\n",
    "total_bytes_columns = [f'{app} Total Bytes' for app in ['Social Media', 'Google', 'Email', 'Youtube', 'Netflix', 'Gaming', 'Other']]\n",
    "total_bytes_data = cleaned_data[total_bytes_columns]\n",
    "\n",
    "# Calculate correlation matrix for total bytes\n",
    "corr_matrix_total_bytes = total_bytes_data.corr()\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(corr_matrix_total_bytes, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=.5)\n",
    "plt.title('Correlation Matrix for Total Bytes')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Select the relevant columns for PCA\n",
    "all_columns_for_pca = ['Social Media DL (Bytes)', 'Social Media UL (Bytes)',\n",
    "                       'Google DL (Bytes)', 'Google UL (Bytes)',\n",
    "                       'Email DL (Bytes)', 'Email UL (Bytes)',\n",
    "                       'Youtube DL (Bytes)', 'Youtube UL (Bytes)',\n",
    "                       'Netflix DL (Bytes)', 'Netflix UL (Bytes)',\n",
    "                       'Gaming DL (Bytes)', 'Gaming UL (Bytes)',\n",
    "                       'Other DL (Bytes)', 'Other UL (Bytes)',\n",
    "                       'Total DL (Bytes)', 'Total UL (Bytes)',\n",
    "                       'Avg RTT DL (ms)', 'Avg RTT UL (ms)',\n",
    "                       'Avg Bearer TP DL (kbps)', 'Avg Bearer TP UL (kbps)',\n",
    "                       'TCP DL Retrans. Vol (Bytes)', 'TCP UL Retrans. Vol (Bytes)',\n",
    "                       'DL TP < 50 Kbps (%)', '50 Kbps < DL TP < 250 Kbps (%)',\n",
    "                       '250 Kbps < DL TP < 1 Mbps (%)', 'DL TP > 1 Mbps (%)',\n",
    "                       'UL TP < 10 Kbps (%)', '10 Kbps < UL TP < 50 Kbps (%)',\n",
    "                       '50 Kbps < UL TP < 300 Kbps (%)', 'UL TP > 300 Kbps (%)',\n",
    "                       'HTTP DL (Bytes)', 'HTTP UL (Bytes)',\n",
    "                       'Activity Duration DL (ms)', 'Activity Duration UL (ms)',\n",
    "                       'Nb of sec with 125000B < Vol DL', 'Nb of sec with 1250B < Vol UL < 6250B',\n",
    "                       'Nb of sec with 31250B < Vol DL < 125000B', 'Nb of sec with 37500B < Vol UL',\n",
    "                       'Nb of sec with 6250B < Vol DL < 31250B', 'Nb of sec with 6250B < Vol UL < 37500B',\n",
    "                       'Nb of sec with Vol DL < 6250B', 'Nb of sec with Vol UL < 1250B']\n",
    "\n",
    "# Create a subset dataframe with relevant columns\n",
    "data_for_pca = cleaned_data[all_columns_for_pca]\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(data_for_pca)\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(10)\n",
    "principal_components = pca.fit_transform(scaled_data)\n",
    "\n",
    "# Get explained variance ratio\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "\n",
    "# Plot explained variance\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(range(1, len(explained_variance_ratio) + 1), explained_variance_ratio, alpha=0.8, align='center')\n",
    "plt.step(range(1, len(explained_variance_ratio) + 1), explained_variance_ratio.cumsum(), where='mid')\n",
    "plt.title('Explained Variance vs. Number of Principal Components')\n",
    "plt.xlabel('Number of Principal Components')\n",
    "plt.ylabel('Explained Variance Ratio')\n",
    "plt.show()\n",
    "\n",
    "principal_components  = pd.DataFrame(principal_components)\n",
    "principal_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
